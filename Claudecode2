# tableau_inventory_with_progress.py
import os
import sys
import subprocess
import pandas as pd
import tableauserverclient as TSC
from datetime import datetime

# ===== EDIT THESE =====
SERVER      = "https://mytableau.cvs.com"   # Root URL (no '/#/')
SITE_ID     = "RX_OPS"                      # e.g., RX_OPS
PAT_NAME    = "YOUR_PAT_NAME"
PAT_SECRET  = "YOUR_PAT_SECRET"

OUTPUT_CSV        = "tableau_inventory.csv"
DOWNLOAD_VIEW_CSV = False                   # True = export underlying data CSVs for each view (needs permission)
VIEW_CSV_DIR      = "view_csvs"
PAGE_SIZE         = 1000                    # Max page size for TSC
# ======================

def print_progress_bar(current, total, prefix='Progress', suffix='Complete', length=50, fill='█'):
    """Print a progress bar to terminal"""
    if total == 0:
        return
    percent = f"{100 * (current / float(total)):.1f}"
    filled_length = int(length * current // total)
    bar = fill * filled_length + '-' * (length - filled_length)
    print(f'\r{prefix} |{bar}| {percent}% {suffix} ({current}/{total})', end='', flush=True)
    if current == total:
        print()  # New line when complete

def link_for_view(server_base, site_id, content_url):
    return f"{server_base}/#/site/{site_id}/views/{content_url}"

def link_for_workbook(server_base, site_id, content_url):
    return f"{server_base}/#/site/{site_id}/workbooks/{content_url}"

def has_more(pagination):
    # TSC pagination: page_number (1-based), page_size, total_available
    return pagination.page_number * pagination.page_size < pagination.total_available

def open_excel(filepath):
    """Force open a file in Excel (Windows). Falls back to default opener on other OS."""
    try:
        if sys.platform.startswith("win"):
            # Try excel.exe via PATH
            subprocess.Popen(["excel.exe", filepath], shell=True)
        elif sys.platform == "darwin":
            subprocess.Popen(["open", "-a", "Microsoft Excel", filepath])
        else:
            subprocess.Popen(["xdg-open", filepath])
    except Exception as e:
        print(f"⚠️ Could not open in Excel: {e}")
        # Fallback to default handler
        try:
            if sys.platform.startswith("win"):
                subprocess.Popen(["start", "", filepath], shell=True)
            elif sys.platform == "darwin":
                subprocess.Popen(["open", filepath])
            else:
                subprocess.Popen(["xdg-open", filepath])
        except Exception as e2:
            print(f"⚠️ Fallback open failed: {e2}")

def open_folder(path):
    try:
        if sys.platform.startswith("win"):
            subprocess.Popen(["explorer", path])
        elif sys.platform == "darwin":
            subprocess.Popen(["open", path])
        else:
            subprocess.Popen(["xdg-open", path])
    except Exception as e:
        print(f"⚠️ Could not open folder: {e}")

def get_total_workbooks(server):
    """Get total count of workbooks for progress calculation"""
    try:
        req = TSC.RequestOptions()
        req.page_size = 1  # Just get count, not data
        _, pagination = server.workbooks.get(req_options=req)
        return pagination.total_available
    except Exception as e:
        print(f"⚠️ Could not get workbook count: {e}")
        return 0

def main():
    print("="*60)
    print("🚀 TABLEAU INVENTORY EXTRACTION")
    print("="*60)
    start_time = datetime.now()
    print(f"⏰ Started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    server = TSC.Server(SERVER, use_server_version=True)
    auth   = TSC.PersonalAccessTokenAuth(PAT_NAME, PAT_SECRET, SITE_ID)

    rows = []

    try:
        with server.auth.sign_in(auth):
            print(f"✅ Successfully connected to {SERVER}")
            print()

            # ---- Get total workbook count first for progress tracking ----
            print("🔍 Getting total workbook count...")
            total_workbooks = get_total_workbooks(server)
            print(f"📊 Total workbooks to process: {total_workbooks:,}")
            print()

            # ---- Projects (paged) ----
            print("📁 Fetching projects...")
            projects_by_id = {}
            preq = TSC.RequestOptions(); preq.page_size = PAGE_SIZE
            project_count = 0
            while True:
                projects, p_page = server.projects.get(req_options=preq)
                for p in projects:
                    projects_by_id[p.id] = p
                    project_count += 1
                
                if p_page.total_available > 0:
                    print_progress_bar(project_count, p_page.total_available, 
                                     prefix='Projects', suffix='fetched')
                
                if has_more(p_page):
                    preq.page_number = p_page.page_number + 1
                else:
                    break
            print(f"✅ Fetched {len(projects_by_id):,} projects")
            print()

            # ---- Datasources (optional, best-effort) ----
            print("💾 Fetching datasources...")
            ds_by_id = {}
            try:
                dreq = TSC.RequestOptions(); dreq.page_size = PAGE_SIZE
                ds_count = 0
                while True:
                    datasources, d_page = server.datasources.get(req_options=dreq)
                    for d in datasources:
                        ds_by_id[d.id] = d
                        ds_count += 1
                    
                    if d_page.total_available > 0:
                        print_progress_bar(ds_count, d_page.total_available, 
                                         prefix='Datasources', suffix='fetched')
                    
                    if has_more(d_page):
                        dreq.page_number = d_page.page_number + 1
                    else:
                        break
            except Exception:
                ds_by_id = {}
            print(f"✅ Fetched {len(ds_by_id):,} datasources")
            print()

            # ---- Preload usage stats for views (safe) ----
            print("📊 Fetching view usage statistics...")
            view_usage_by_id = {}
            try:
                vreq = TSC.RequestOptions()
                vreq.page_size = PAGE_SIZE
                vreq.include_usage_statistics = True
                view_count = 0
                while True:
                    views_page, v_page = server.views.get(req_options=vreq)
                    for vv in views_page:
                        view_usage_by_id[vv.id] = getattr(vv, "total_views", None)
                        view_count += 1
                    
                    if v_page.total_available > 0:
                        print_progress_bar(view_count, v_page.total_available, 
                                         prefix='View Stats', suffix='fetched')
                    
                    if has_more(v_page):
                        vreq.page_number = v_page.page_number + 1
                    else:
                        break
            except Exception:
                view_usage_by_id = {}
            print(f"✅ Fetched usage stats for {len(view_usage_by_id):,} views")
            print()

            # ---- Workbooks (paged) with progress tracking ----
            print("="*60)
            print("📚 PROCESSING WORKBOOKS & VIEWS")
            print("="*60)
            
            wb_req = TSC.RequestOptions(); wb_req.page_size = PAGE_SIZE
            processed_workbooks = 0
            
            while True:
                workbooks, w_page = server.workbooks.get(req_options=wb_req)

                for wb in workbooks:
                    processed_workbooks += 1
                    
                    # Update progress bar
                    if total_workbooks > 0:
                        print_progress_bar(processed_workbooks, total_workbooks, 
                                         prefix='📚 Workbooks', suffix='processed')
                    
                    # Log every 25 workbooks
                    if processed_workbooks % 25 == 0:
                        print(f"\n📈 Progress: {processed_workbooks:,}/{total_workbooks:,} workbooks "
                              f"({100*processed_workbooks/total_workbooks:.1f}%) - Current: {wb.name[:50]}...")

                    # Populate views & connections for this workbook
                    try:
                        server.workbooks.populate_views(wb)
                    except Exception:
                        wb.views = []

                    try:
                        server.workbooks.populate_connections(wb)
                    except Exception:
                        wb.connections = []

                    proj   = projects_by_id.get(wb.project_id)
                    wb_url = link_for_workbook(SERVER, SITE_ID, wb.content_url)

                    # Datasource hints
                    ds_names, ds_types = [], []
                    for c in getattr(wb, "connections", []):
                        ds_obj = ds_by_id.get(getattr(c, "datasource_id", None))
                        if ds_obj:
                            ds_names.append(ds_obj.name or "")
                            ds_types.append(ds_obj.connection_type or "")
                        else:
                            ds_names.append(getattr(c, "server_address", "") or "embedded/unknown")
                            ds_types.append(getattr(c, "connection_type", "") or "unknown")

                    for v in getattr(wb, "views", []):
                        v_url = link_for_view(SERVER, SITE_ID, v.content_url)
                        total_views = view_usage_by_id.get(v.id, None)  # don't touch v.total_views directly

                        saved_csv_path = None
                        if DOWNLOAD_VIEW_CSV:
                            try:
                                os.makedirs(VIEW_CSV_DIR, exist_ok=True)
                                csv_bytes = server.views.populate_csv(v)  # requires "Download Full Data"
                                safe = f"{(proj.name if proj else 'NoProject')}__{wb.name}__{v.name}".replace("/", "_").replace("\\", "_")
                                saved_csv_path = os.path.join(VIEW_CSV_DIR, f"{safe}.csv")
                                with open(saved_csv_path, "wb") as f:
                                    f.write(csv_bytes)
                            except Exception as e:
                                saved_csv_path = f"ERROR: {e}"

                        rows.append({
                            "project_name":      proj.name if proj else None,
                            "project_id":        wb.project_id,
                            "workbook_name":     wb.name,
                            "workbook_id":       wb.id,
                            "workbook_url":      wb_url,
                            "workbook_created":  getattr(wb, "created_at", None),
                            "workbook_updated":  getattr(wb, "updated_at", None),
                            "owner_id":          getattr(wb, "owner_id", None),  # UUID; we avoid /users
                            "view_name":         v.name,
                            "view_id":           v.id,
                            "view_url":          v_url,
                            "view_total_views":  total_views,
                            "datasource_names":  "; ".join(sorted(set(n for n in ds_names if n))),
                            "datasource_types":  "; ".join(sorted(set(t for t in ds_types if t))),
                            "saved_view_csv":    saved_csv_path
                        })

                if has_more(w_page):
                    wb_req.page_number = w_page.page_number + 1
                else:
                    break

    except KeyboardInterrupt:
        print(f"\n\n⚠️ Extraction interrupted by user!")
        print(f"📊 Processed {processed_workbooks:,} workbooks so far")
        if len(rows) > 0:
            print("💾 Saving partial results...")
        else:
            print("❌ No data to save")
            return

    # ---- Save & report path ----
    print(f"\n\n" + "="*60)
    print("💾 SAVING RESULTS")
    print("="*60)
    
    output_path = os.path.abspath(OUTPUT_CSV)
    df = pd.DataFrame(rows)
    
    if len(df) > 0:
        df_sorted = df.sort_values(
            ["project_name", "workbook_name", "view_name"], na_position="last"
        )
        df_sorted.to_csv(output_path, index=False)

        # Summary statistics
        total_projects = df['project_id'].nunique()
        total_workbooks_found = df['workbook_id'].nunique()
        total_views = len(df)
        
        end_time = datetime.now()
        duration = end_time - start_time

        print("="*60)
        print("🎉 EXTRACTION COMPLETED!")
        print("="*60)
        print(f"📊 SUMMARY:")
        print(f"   🗂️  Projects: {total_projects:,}")
        print(f"   📚 Workbooks: {total_workbooks_found:,}")
        print(f"   📄 Views: {total_views:,}")
        print(f"   ⏱️  Duration: {duration}")
        print(f"   📁 Output: {output_path}")

        if DOWNLOAD_VIEW_CSV:
            print(f"   📂 Per-view CSVs: {os.path.abspath(VIEW_CSV_DIR)}")

        # ---- Force open in Excel + open per-view folder if used ----
        print(f"\n🚀 Opening Excel...")
        open_excel(output_path)
        if DOWNLOAD_VIEW_CSV:
            open_folder(os.path.abspath(VIEW_CSV_DIR))
    else:
        print("❌ No data was extracted!")

if __name__ == "__main__":
    main()
