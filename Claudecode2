# tableau_inventory_with_progress.py
import os
import sys
import subprocess
import pandas as pd
import tableauserverclient as TSC
from datetime import datetime

# ===== EDIT THESE =====
SERVER      = "https://mytableau.cvs.com"   # Root URL (no '/#/')
SITE_ID     = "RX_OPS"                      # e.g., RX_OPS
PAT_NAME    = "YOUR_PAT_NAME"
PAT_SECRET  = "YOUR_PAT_SECRET"

OUTPUT_CSV        = "tableau_inventory.csv"
DOWNLOAD_VIEW_CSV = False                   # True = export underlying data CSVs for each view (needs permission)
VIEW_CSV_DIR      = "view_csvs"
PAGE_SIZE         = 1000                    # Max page size for TSC
# ======================

def print_progress_bar(current, total, prefix='Progress', suffix='Complete', length=50, fill='‚ñà'):
    """Print a progress bar to terminal"""
    if total == 0:
        return
    percent = f"{100 * (current / float(total)):.1f}"
    filled_length = int(length * current // total)
    bar = fill * filled_length + '-' * (length - filled_length)
    print(f'\r{prefix} |{bar}| {percent}% {suffix} ({current}/{total})', end='', flush=True)
    if current == total:
        print()  # New line when complete

def link_for_view(server_base, site_id, content_url):
    return f"{server_base}/#/site/{site_id}/views/{content_url}"

def link_for_workbook(server_base, site_id, content_url):
    return f"{server_base}/#/site/{site_id}/workbooks/{content_url}"

def has_more(pagination):
    # TSC pagination: page_number (1-based), page_size, total_available
    return pagination.page_number * pagination.page_size < pagination.total_available

def open_excel(filepath):
    """Force open a file in Excel (Windows). Falls back to default opener on other OS."""
    try:
        if sys.platform.startswith("win"):
            # Try excel.exe via PATH
            subprocess.Popen(["excel.exe", filepath], shell=True)
        elif sys.platform == "darwin":
            subprocess.Popen(["open", "-a", "Microsoft Excel", filepath])
        else:
            subprocess.Popen(["xdg-open", filepath])
    except Exception as e:
        print(f"‚ö†Ô∏è Could not open in Excel: {e}")
        # Fallback to default handler
        try:
            if sys.platform.startswith("win"):
                subprocess.Popen(["start", "", filepath], shell=True)
            elif sys.platform == "darwin":
                subprocess.Popen(["open", filepath])
            else:
                subprocess.Popen(["xdg-open", filepath])
        except Exception as e2:
            print(f"‚ö†Ô∏è Fallback open failed: {e2}")

def open_folder(path):
    try:
        if sys.platform.startswith("win"):
            subprocess.Popen(["explorer", path])
        elif sys.platform == "darwin":
            subprocess.Popen(["open", path])
        else:
            subprocess.Popen(["xdg-open", path])
    except Exception as e:
        print(f"‚ö†Ô∏è Could not open folder: {e}")

def get_total_workbooks(server):
    """Get total count of workbooks for progress calculation"""
    try:
        req = TSC.RequestOptions()
        req.page_size = 1  # Just get count, not data
        _, pagination = server.workbooks.get(req_options=req)
        return pagination.total_available
    except Exception as e:
        print(f"‚ö†Ô∏è Could not get workbook count: {e}")
        return 0

def main():
    print("="*60)
    print("üöÄ TABLEAU INVENTORY EXTRACTION")
    print("="*60)
    start_time = datetime.now()
    print(f"‚è∞ Started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    server = TSC.Server(SERVER, use_server_version=True)
    auth   = TSC.PersonalAccessTokenAuth(PAT_NAME, PAT_SECRET, SITE_ID)

    rows = []

    try:
        with server.auth.sign_in(auth):
            print(f"‚úÖ Successfully connected to {SERVER}")
            print()

            # ---- Get total workbook count first for progress tracking ----
            print("üîç Getting total workbook count...")
            total_workbooks = get_total_workbooks(server)
            print(f"üìä Total workbooks to process: {total_workbooks:,}")
            print()

            # ---- Projects (paged) ----
            print("üìÅ Fetching projects...")
            projects_by_id = {}
            preq = TSC.RequestOptions(); preq.page_size = PAGE_SIZE
            project_count = 0
            while True:
                projects, p_page = server.projects.get(req_options=preq)
                for p in projects:
                    projects_by_id[p.id] = p
                    project_count += 1
                
                if p_page.total_available > 0:
                    print_progress_bar(project_count, p_page.total_available, 
                                     prefix='Projects', suffix='fetched')
                
                if has_more(p_page):
                    preq.page_number = p_page.page_number + 1
                else:
                    break
            print(f"‚úÖ Fetched {len(projects_by_id):,} projects")
            print()

            # ---- Datasources (optional, best-effort) ----
            print("üíæ Fetching datasources...")
            ds_by_id = {}
            try:
                dreq = TSC.RequestOptions(); dreq.page_size = PAGE_SIZE
                ds_count = 0
                while True:
                    datasources, d_page = server.datasources.get(req_options=dreq)
                    for d in datasources:
                        ds_by_id[d.id] = d
                        ds_count += 1
                    
                    if d_page.total_available > 0:
                        print_progress_bar(ds_count, d_page.total_available, 
                                         prefix='Datasources', suffix='fetched')
                    
                    if has_more(d_page):
                        dreq.page_number = d_page.page_number + 1
                    else:
                        break
            except Exception:
                ds_by_id = {}
            print(f"‚úÖ Fetched {len(ds_by_id):,} datasources")
            print()

            # ---- Preload usage stats for views (safe) ----
            print("üìä Fetching view usage statistics...")
            view_usage_by_id = {}
            try:
                vreq = TSC.RequestOptions()
                vreq.page_size = PAGE_SIZE
                vreq.include_usage_statistics = True
                view_count = 0
                while True:
                    views_page, v_page = server.views.get(req_options=vreq)
                    for vv in views_page:
                        view_usage_by_id[vv.id] = getattr(vv, "total_views", None)
                        view_count += 1
                    
                    if v_page.total_available > 0:
                        print_progress_bar(view_count, v_page.total_available, 
                                         prefix='View Stats', suffix='fetched')
                    
                    if has_more(v_page):
                        vreq.page_number = v_page.page_number + 1
                    else:
                        break
            except Exception:
                view_usage_by_id = {}
            print(f"‚úÖ Fetched usage stats for {len(view_usage_by_id):,} views")
            print()

            # ---- Workbooks (paged) with progress tracking ----
            print("="*60)
            print("üìö PROCESSING WORKBOOKS & VIEWS")
            print("="*60)
            
            wb_req = TSC.RequestOptions(); wb_req.page_size = PAGE_SIZE
            processed_workbooks = 0
            
            while True:
                workbooks, w_page = server.workbooks.get(req_options=wb_req)

                for wb in workbooks:
                    processed_workbooks += 1
                    
                    # Update progress bar
                    if total_workbooks > 0:
                        print_progress_bar(processed_workbooks, total_workbooks, 
                                         prefix='üìö Workbooks', suffix='processed')
                    
                    # Log every 25 workbooks
                    if processed_workbooks % 25 == 0:
                        print(f"\nüìà Progress: {processed_workbooks:,}/{total_workbooks:,} workbooks "
                              f"({100*processed_workbooks/total_workbooks:.1f}%) - Current: {wb.name[:50]}...")

                    # Populate views & connections for this workbook
                    try:
                        server.workbooks.populate_views(wb)
                    except Exception:
                        wb.views = []

                    try:
                        server.workbooks.populate_connections(wb)
                    except Exception:
                        wb.connections = []

                    proj   = projects_by_id.get(wb.project_id)
                    wb_url = link_for_workbook(SERVER, SITE_ID, wb.content_url)

                    # Datasource hints
                    ds_names, ds_types = [], []
                    for c in getattr(wb, "connections", []):
                        ds_obj = ds_by_id.get(getattr(c, "datasource_id", None))
                        if ds_obj:
                            ds_names.append(ds_obj.name or "")
                            ds_types.append(ds_obj.connection_type or "")
                        else:
                            ds_names.append(getattr(c, "server_address", "") or "embedded/unknown")
                            ds_types.append(getattr(c, "connection_type", "") or "unknown")

                    for v in getattr(wb, "views", []):
                        v_url = link_for_view(SERVER, SITE_ID, v.content_url)
                        total_views = view_usage_by_id.get(v.id, None)  # don't touch v.total_views directly

                        saved_csv_path = None
                        if DOWNLOAD_VIEW_CSV:
                            try:
                                os.makedirs(VIEW_CSV_DIR, exist_ok=True)
                                csv_bytes = server.views.populate_csv(v)  # requires "Download Full Data"
                                safe = f"{(proj.name if proj else 'NoProject')}__{wb.name}__{v.name}".replace("/", "_").replace("\\", "_")
                                saved_csv_path = os.path.join(VIEW_CSV_DIR, f"{safe}.csv")
                                with open(saved_csv_path, "wb") as f:
                                    f.write(csv_bytes)
                            except Exception as e:
                                saved_csv_path = f"ERROR: {e}"

                        rows.append({
                            "project_name":      proj.name if proj else None,
                            "project_id":        wb.project_id,
                            "workbook_name":     wb.name,
                            "workbook_id":       wb.id,
                            "workbook_url":      wb_url,
                            "workbook_created":  getattr(wb, "created_at", None),
                            "workbook_updated":  getattr(wb, "updated_at", None),
                            "owner_id":          getattr(wb, "owner_id", None),  # UUID; we avoid /users
                            "view_name":         v.name,
                            "view_id":           v.id,
                            "view_url":          v_url,
                            "view_total_views":  total_views,
                            "datasource_names":  "; ".join(sorted(set(n for n in ds_names if n))),
                            "datasource_types":  "; ".join(sorted(set(t for t in ds_types if t))),
                            "saved_view_csv":    saved_csv_path
                        })

                if has_more(w_page):
                    wb_req.page_number = w_page.page_number + 1
                else:
                    break

    except KeyboardInterrupt:
        print(f"\n\n‚ö†Ô∏è Extraction interrupted by user!")
        print(f"üìä Processed {processed_workbooks:,} workbooks so far")
        if len(rows) > 0:
            print("üíæ Saving partial results...")
        else:
            print("‚ùå No data to save")
            return

    # ---- Save & report path ----
    print(f"\n\n" + "="*60)
    print("üíæ SAVING RESULTS")
    print("="*60)
    
    output_path = os.path.abspath(OUTPUT_CSV)
    df = pd.DataFrame(rows)
    
    if len(df) > 0:
        df_sorted = df.sort_values(
            ["project_name", "workbook_name", "view_name"], na_position="last"
        )
        df_sorted.to_csv(output_path, index=False)

        # Summary statistics
        total_projects = df['project_id'].nunique()
        total_workbooks_found = df['workbook_id'].nunique()
        total_views = len(df)
        
        end_time = datetime.now()
        duration = end_time - start_time

        print("="*60)
        print("üéâ EXTRACTION COMPLETED!")
        print("="*60)
        print(f"üìä SUMMARY:")
        print(f"   üóÇÔ∏è  Projects: {total_projects:,}")
        print(f"   üìö Workbooks: {total_workbooks_found:,}")
        print(f"   üìÑ Views: {total_views:,}")
        print(f"   ‚è±Ô∏è  Duration: {duration}")
        print(f"   üìÅ Output: {output_path}")

        if DOWNLOAD_VIEW_CSV:
            print(f"   üìÇ Per-view CSVs: {os.path.abspath(VIEW_CSV_DIR)}")

        # ---- Force open in Excel + open per-view folder if used ----
        print(f"\nüöÄ Opening Excel...")
        open_excel(output_path)
        if DOWNLOAD_VIEW_CSV:
            open_folder(os.path.abspath(VIEW_CSV_DIR))
    else:
        print("‚ùå No data was extracted!")

if __name__ == "__main__":
    main()
